RL算法的state和action分别为：

state的组成为:( relative_position: 3, [normalized_distance:  1] , direction_to_goal: 3, [scalar_distance: 1], sensor_readings: 12)



state:[ 0.5 0.16666667  -0.12796831  0.31313132  0.92189801  0.30729935 -0.23594746  0.31313132
        1.  0.33333331  1.          0.33333331
        0.88888896  0.11111112  1.          0.44444448  0.44444448  0.44444448
          1.          0.11111112],
action:[9.328627  5.7203794 1.5356197]

state:[ 0.33333334  0.         -0.17648165  0.21775895  0.88377577  0.
 -0.46791062  0.21775895  0.77777779  0.55555552  0.77777779  0.55555552
  0.88888896  0.44444448  1.          0.77777779  0.77777779  0.77777779
  1.          0.44444448],
 action:[8.905344  3.8101773 0.5821601]

state:[ 0.16666667 -0.08273169 -0.13593172  0.13304102  0.72327352 -0.35902581
 -0.58989483  0.13304102  0.55555552  0.77777779  0.66666663  0.66666663
  0.88888896  0.11111112  0.77777779  0.77777779  0.88888896  0.88888896
  0.88888896  0.11111112]
action:[ 6.871931    0.99278015 -0.48659927]


state:[ 0.          0.01543732 -0.04078837  0.02517937  0.          0.35397005
 -0.93525672  0.02517937  0.33333331  0.22222224  0.66666663  0.55555552
  1.          0.33333331  0.44444448  0.44444448  0.33333331  0.33333331
  1.          0.44444448]
action:[ 4.6700225 -1.1780281 -1.1417202]




实际使用Teacher的输出为 只有位置信息

[(1.0, 1.0, 2.0), (1.716420769839612, 1.6974022933942434, 2.0192697096726206),
(2.00669031698622, 2.3880486328611017, 2.6816526984188087), (2.9308578493209367, 2.6807118240874344, 2.92713717589056),
(2.9139824248884163, 2.8282470815625986, 3.9160499970492095), (3.3175071931858087, 3.5669174201374565, 4.455988782727958),
(3.3532133044793677, 4.524061329401431, 4.168585563234564), (4.104397529708384, 4.97002879246854, 4.655242815982912),
(9.0, 5.0, 2.0)]


1. 需要一个函数 用下一个状态把上一个状态减去 得到（n-1）个动作然后得限制动作在[-1,1]之间

2. 根据state的组成 :
    relative_position =
